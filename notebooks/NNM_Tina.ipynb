{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set up env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current workpath: /home/tina4aiml/dev/notebooks\n",
      "Parent_folder: /home/tina4aiml/dev\n",
      "/home/tina4aiml/dev/src\n"
     ]
    }
   ],
   "source": [
    "# for Tina machine only, to import .py from src/ds/\n",
    "import os\n",
    "current_workpath = os.getcwd()\n",
    "print(\"Current workpath:\", current_workpath)\n",
    "\n",
    "parent_folder = os.path.dirname(current_workpath)\n",
    "print(\"Parent_folder:\", parent_folder)\n",
    "\n",
    "import sys\n",
    "sys.path.append(parent_folder+'/src')\n",
    "print(sys.path[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawfile_name = 'beer_reviews'\n",
    "rawfile_format = '.csv'\n",
    "rawfile_path = \"../data/raw/\"\n",
    "datadict_path = \"../references/Data_Dict.csv\"\n",
    "\n",
    "interim_folder_path = \"../data/interim/\"\n",
    "processed_folder_path  =\"../data/processed/\"\n",
    "model_folder_path = \"../models/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import split datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ds.data.sets import load_sets_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_v2, y_train_v2, X_val_v2, y_val_v2, X_test_v2, y_test_v2 = load_sets_v2(path='../data/processed/', suffix='_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_v2 shape: (951968, 6)\n",
      "y_train_v2 shape: (951968,)\n",
      "X_val_v2 shape: (317323, 6)\n",
      "y_val_v2 shape: (317323,)\n",
      "X_test_v2 shape: (317323, 6)\n",
      "y_test_v2 shape: (317323,)\n"
     ]
    }
   ],
   "source": [
    "# Check if the datasets were loaded successfully\n",
    "if X_train_v2 is not None:\n",
    "    print(\"X_train_v2 shape:\", X_train_v2.shape) # (951968, 6)\n",
    "else:\n",
    "    print(\"X_train_v2 file not found\")\n",
    "\n",
    "if y_train_v2 is not None:\n",
    "    print(\"y_train_v2 shape:\", y_train_v2.shape) #(951968,)\n",
    "else:\n",
    "    print(\"y_train_v2 file not found\") \n",
    "\n",
    "if X_val_v2 is not None:\n",
    "    print(\"X_val_v2 shape:\", X_val_v2.shape) # (317323, 6)\n",
    "else:\n",
    "    print(\"X_val_v2 file not found\")\n",
    "\n",
    "if y_val_v2 is not None:\n",
    "    print(\"y_val_v2 shape:\", y_val_v2.shape) # (317323,)\n",
    "else:\n",
    "    print(\"y_val_v2 file not found\")\n",
    "\n",
    "if X_test_v2 is not None:\n",
    "    print(\"X_test_v2 shape:\", X_test_v2.shape) # (317323, 6)\n",
    "else:\n",
    "    print(\"X_test_v2 file not found\")\n",
    "\n",
    "if y_test_v2 is not None:\n",
    "    print(\"y_test_v2 shape:\", y_test_v2.shape) # (317323,)\n",
    "else:\n",
    "    print(\"y_test_v2 file not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brewery_name',\n",
       " 'review_aroma',\n",
       " 'review_appearance',\n",
       " 'review_palate',\n",
       " 'review_taste',\n",
       " 'beer_abv']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = pd.read_csv(datadict_path)\n",
    "features_label = data_dict.loc[data_dict['API Expected Parameter'] == 'Yes', 'Column'].tolist()\n",
    "features_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(processed_folder_path + \"/features_label.npy\", features_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_label = np.load(processed_folder_path+'features_label.npy',allow_pickle=True)\n",
    "features_label_n = len(features_label)\n",
    "features_label_n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_class = np.load(processed_folder_path+'beer_style.npy',allow_pickle=True)\n",
    "target_class_n = len(target_class)\n",
    "target_class_n "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 00:11:14.965898: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-07 00:11:15.151922: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-07 00:11:17.661107: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-07 00:11:17.703611: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-07 00:11:17.704176: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-07 00:11:17.719713: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-07 00:11:17.719991: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-07 00:11:17.720124: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-07 00:11:20.645031: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-07 00:11:20.645655: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-07 00:11:20.645676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-07-07 00:11:20.646256: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-07 00:11:20.646402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3383 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 00:11:25.824960: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-07-07 00:11:25.834312: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f110cc7d950 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-07-07 00:11:25.834367: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2023-07-07 00:11:25.847189: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-07-07 00:11:26.097993: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-07-07 00:11:26.302165: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29749/29749 [==============================] - 138s 4ms/step - loss: 3.3165 - accuracy: 0.1848 - val_loss: 3.2220 - val_accuracy: 0.1944\n",
      "Epoch 2/10\n",
      "29749/29749 [==============================] - 141s 5ms/step - loss: 3.1847 - accuracy: 0.2026 - val_loss: 3.1498 - val_accuracy: 0.2101\n",
      "Epoch 3/10\n",
      "29749/29749 [==============================] - 132s 4ms/step - loss: 3.1288 - accuracy: 0.2142 - val_loss: 3.1055 - val_accuracy: 0.2211\n",
      "Epoch 4/10\n",
      "29749/29749 [==============================] - 127s 4ms/step - loss: 3.0883 - accuracy: 0.2242 - val_loss: 3.0800 - val_accuracy: 0.2266\n",
      "Epoch 5/10\n",
      "29749/29749 [==============================] - 131s 4ms/step - loss: 3.0579 - accuracy: 0.2318 - val_loss: 3.0450 - val_accuracy: 0.2360\n",
      "Epoch 6/10\n",
      "29749/29749 [==============================] - 146s 5ms/step - loss: 3.0342 - accuracy: 0.2372 - val_loss: 3.0269 - val_accuracy: 0.2398\n",
      "Epoch 7/10\n",
      "29749/29749 [==============================] - 132s 4ms/step - loss: 3.0146 - accuracy: 0.2430 - val_loss: 3.0137 - val_accuracy: 0.2427\n",
      "Epoch 8/10\n",
      "29749/29749 [==============================] - 141s 5ms/step - loss: 2.9983 - accuracy: 0.2476 - val_loss: 3.0037 - val_accuracy: 0.2454\n",
      "Epoch 9/10\n",
      "29749/29749 [==============================] - 139s 5ms/step - loss: 2.9839 - accuracy: 0.2523 - val_loss: 2.9788 - val_accuracy: 0.2496\n",
      "Epoch 10/10\n",
      "29749/29749 [==============================] - 145s 5ms/step - loss: 2.9709 - accuracy: 0.2562 - val_loss: 2.9673 - val_accuracy: 0.2593\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.utils.set_random_seed(1)\n",
    "\n",
    "input_shape = (features_label_n,)\n",
    "num_classes = target_class_n\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=input_shape),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train_v2, y_train_v2, epochs=10, batch_size=32, validation_data=(X_val_v2, y_val_v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model history to a file\n",
    "import pickle\n",
    "with open('model_history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/NNM_Tina_v1.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "dump(model, model_folder_path + 'NNM_Tina_v1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29749/29749 [==============================] - 37s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_train_v2_pred_probs = model.predict(X_train_v2)\n",
    "y_train_v2_pred = y_train_v2_pred_probs.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(951968,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_v2_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  9, 12, ..., 11, 39, 98])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_v2_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2599593683821305\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_train_v2, y_train_v2_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_v2_pred_probs = model.predict(X_train_v2)\n",
    "y_train_v2_pred = y_train_v2_pred_probs.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9917/9917 [==============================] - 14s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_v2_pred_probs = model.predict(X_test_v2)\n",
    "y_test_v2_pred = y_test_v2_pred_probs.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2584086246505926\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test_v2, y_test_v2_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline: Xgboost model is 0.29106304932198424\n",
    "# accuracy is low might becasue we hash the brewey_name in 10 groups. 'MemoryError' when try to hash all with HashingVectorizer() from sklearn.feature_extraction.text.\n",
    "\n",
    "# no validation defined 'brewery_name' bucket increase to 10, KNN nearby 5,in the model Test accuracy: 0.24678009748458862\n",
    "# with validation dataset in the model , 'brewery_name' bucket increase to 10, KNN nearby 5, test accuracy:0.24332934617996216\n",
    "# with validation ds defined, 'brewery_name' bucket increase to 1000, KNN nearby increase to 10, Accuracy: 0.2584086246505926"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot model evaluation\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('Model Evaluation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Loss', 'Accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explain the before and after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9917/9917 [==============================] - 12s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_val_v2_pred_probs = model.predict(X_val_v2)\n",
    "y_val_v2_pred = y_val_v2_pred_probs.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   9, 103, ...,  44,   9, 100])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_v2_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16, 60, 65, ..., 47,  9, 19])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = accuracy_score(y_val_v2, y_val_v2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2592910063247858"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: 16",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/_encode.py:225\u001b[0m, in \u001b[0;36m_encode\u001b[0;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     \u001b[39mreturn\u001b[39;00m _map_to_integer(values, uniques)\n\u001b[1;32m    226\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/_encode.py:165\u001b[0m, in \u001b[0;36m_map_to_integer\u001b[0;34m(values, uniques)\u001b[0m\n\u001b[1;32m    164\u001b[0m table \u001b[39m=\u001b[39m _nandict({val: i \u001b[39mfor\u001b[39;00m i, val \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(uniques)})\n\u001b[0;32m--> 165\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([table[v] \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m values])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/_encode.py:165\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    164\u001b[0m table \u001b[39m=\u001b[39m _nandict({val: i \u001b[39mfor\u001b[39;00m i, val \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(uniques)})\n\u001b[0;32m--> 165\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([table[v] \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m values])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/_encode.py:159\u001b[0m, in \u001b[0;36m_nandict.__missing__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnan_value\n\u001b[0;32m--> 159\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 16",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39m# Load the LabelEncoder object\u001b[39;00m\n\u001b[1;32m      5\u001b[0m label_encoder \u001b[39m=\u001b[39m load(model_folder_path\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlabel_encoder.joblib\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m encoded_labels \u001b[39m=\u001b[39m label_encoder\u001b[39m.\u001b[39;49mtransform(y_val_v2)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:137\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mif\u001b[39;00m _num_samples(y) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    135\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([])\n\u001b[0;32m--> 137\u001b[0m \u001b[39mreturn\u001b[39;00m _encode(y, uniques\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclasses_)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/_encode.py:227\u001b[0m, in \u001b[0;36m_encode\u001b[0;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[39mreturn\u001b[39;00m _map_to_integer(values, uniques)\n\u001b[1;32m    226\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 227\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my contains previously unseen labels: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(e)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    228\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m check_unknown:\n",
      "\u001b[0;31mValueError\u001b[0m: y contains previously unseen labels: 16"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from joblib import load\n",
    "\n",
    "# Load the LabelEncoder object\n",
    "label_encoder = load(model_folder_path+'label_encoder.joblib')\n",
    "\n",
    "encoded_labels = label_encoder.transform(y_val_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_v2_pred_uni = np.unique(y_val_v2_pred, axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_v2_uni = np.unique(y_val_v2, axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 from y_val_v2_uni\n",
      "6 from y_val_v2_uni\n",
      "8 from y_val_v2_uni\n",
      "23 from y_val_v2_uni\n",
      "29 from y_val_v2_uni\n",
      "32 from y_val_v2_uni\n",
      "38 from y_val_v2_uni\n",
      "46 from y_val_v2_uni\n",
      "48 from y_val_v2_uni\n",
      "50 from y_val_v2_uni\n",
      "51 from y_val_v2_uni\n",
      "52 from y_val_v2_uni\n",
      "56 from y_val_v2_uni\n",
      "57 from y_val_v2_uni\n",
      "64 from y_val_v2_uni\n",
      "68 from y_val_v2_uni\n",
      "70 from y_val_v2_uni\n",
      "71 from y_val_v2_uni\n",
      "88 from y_val_v2_uni\n",
      "91 from y_val_v2_uni\n",
      "95 from y_val_v2_uni\n",
      "97 from y_val_v2_uni\n"
     ]
    }
   ],
   "source": [
    "difference = np.setdiff1d(y_val_v2_uni, y_val_v2_pred_uni)\n",
    "\n",
    "# Check which elements in difference are present in y_val_v2_uni\n",
    "in_y_val_v2_uni = np.in1d(difference, y_val_v2_uni)\n",
    "\n",
    "# Check which elements in difference are present in y_val_v2_pred_uni\n",
    "in_y_val_v2_pred_uni = np.in1d(difference, y_val_v2_pred_uni)\n",
    "\n",
    "# Print the elements and their source\n",
    "for i, val in enumerate(difference):\n",
    "    if in_y_val_v2_uni[i]:\n",
    "        print(val, \"from y_val_v2_uni\")\n",
    "    elif in_y_val_v2_pred_uni[i]:\n",
    "        print(val, \"from y_val_v2_pred_uni\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original_target_encoded = df_prep_imputed['beer_style'].unique()\n",
    "original_target_encoded = [ 65,  51,  59,  61,   9,  66,  76,  83,  15,  87,  14,  17,  25,\n",
    "        12,  18,  89,   2,  19,  82,   1,   6,  53,  44,  94,  60,  11,\n",
    "        24,  43,  49,  67,   4,  26,  37,  78,  85,  38,  54,  52,  77,\n",
    "       100,  55,  31,  46,   0,  73,  80,  90,  16,  79,  93,  99,   3,\n",
    "        95, 103,   5,  92,  42,  45,  33,  36,  47,  23,  98,  57,   7,\n",
    "       102,  97,  39,  58,  40,  88,  70,  22,  29,  69,  30,  68,  34,\n",
    "        50,  35,  20,  10,  96, 101,   8,  13,  21,  81,  71,  48,  74,\n",
    "        84,  86,  32,  75,  41,  27,  72,  56,  63,  62,  64,  91,  28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No difference between y_val_v2_uni and original_target_encoded\n"
     ]
    }
   ],
   "source": [
    "# Calculate the difference\n",
    "difference = np.setdiff1d(y_val_v2_uni, original_target_encoded)\n",
    "\n",
    "# Check if there is any difference\n",
    "if difference.size == 0:\n",
    "    print(\"No difference between y_val_v2_uni and original_target_encoded\")\n",
    "else:\n",
    "    # Check which elements in difference are present in original_target_encoded\n",
    "    in_original_target_encoded_uni = np.in1d(difference, original_target_encoded)\n",
    "\n",
    "    # Check which elements in difference are present in y_val_v2_pred_uni\n",
    "    in_y_val_v2_pred_uni = np.in1d(difference, y_val_v2_pred_uni)\n",
    "\n",
    "    # Print the elements and their source\n",
    "    for i, val in enumerate(difference):\n",
    "        if in_original_target_encoded_uni[i]:\n",
    "            print(val, \"from original_target_encoded\")\n",
    "        elif in_y_val_v2_pred_uni[i]:\n",
    "            print(val, \"from y_val_v2_pred_uni\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue:\n",
    "1) unable to convert the encoded label of the validation prediction back to text, as y contains previously unseen labels: 16, but all of them are from the validation dataset.\n",
    "1.2) check the label encorder, no difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_v2_pred = pd.concat([X_val_v2, encoded_labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "result = permutation_importance(model, X_train_v2, y_train_v2, scoring='accuracy')\n",
    "importances = result.importances_mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
